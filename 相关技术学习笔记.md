# 相关技术学习经验

## 调用大模型实现一些功能

## 关于检索

### 检索基本知识

> 也就是从知识库中，检索到与查询向量相似的向量（`top-k`）

包括以下步骤：

- 构建向量数据库

  - 一般是基于 `ANN`（近邻相似）构建（导航小世界，聚类等等）
- 查询，根据构建好的向量数据量，基于导航小世界或聚类进行查询相邻的

### 检索优化

> 主要从以下三个方面进行
>
> - 检索精度
> - 性能效率
> - 异步并发

- 检索精度

  - 模型选择：`embedding model`的选择，最好是适配领域的专业嵌入模型
  - 优化切片：

    - 基于语义进行 `chunk`
    - 保留上下文

      ```python
      page_content = f"[模块:{module_name}] {raw_text}]""
      ```
    - 提供元数据：章节页码
    - 

## MCP

## SDK

> 将 `API`接口进行封装 `API+工具+约定`

## Workflow与Agent的一些理解

## ReAct

## Agent 建设方向

### 意图理解

### 意图预测

### 复杂任务的规划与调度

### 意图执行

## NL2SQL与NL2Cypher

### 基本背景

- 实体抽取（Entity Extraction）：把自然语言里的名词，对应到图数据库里的 **节点（Node）**或**属性值（Property Value）** 。--这里会涉及到实体对齐/归一化
- 关系理解（Relation Understanding）：把自然语言里的动词或连接词，对应到图数据库里的 有向**边（Edge/Relationship）** 。
- 模式拼装（QueryGeneration）:把零散的零件，套进 `MATCH...WHERE...RETURN` 这种固定的**语法模板**里，变成一行数据库能读懂的代码。

**衍生任务**

- 实体对齐（Entity Alignment,EA）任务。类似于匹配任务，相关方法：
  1. 相似度计算
  2. 上下文辅助
  3. 知识库链接

### NL2Cypher

> - 定义：在某个知识图谱的基础上（`KG`），将自然语言查询转化为标准的Cypher查询语言。人类的自然语言指令（如中文或英文）自动转换为数据库查询语言的技术。
> - 用途：打破数据与非技术人员的屏障，具体而言：
>   1. 自助数据分析（排序，查询等等）
>   2. 智能客服与知识库问答：通过精确查询数据库，补充知识库，给到精准反馈
>   3. 复杂关系挖掘或推理（`Cypher`）

- Schema：图数据库或KG中的结构定义。它描述了知识图谱中有哪些节点类型、关系类型以及它们的属性。通常包含以下：
  ```python
  # 节点类型(Labels): Person, Movie, Company
  # 关系类型(Relations): ACTED_IN, DIRECTED, WORKS_FOR
  # 属性(Properties): name, age, title, release_year
  {
    "nodes": ["Person", "Movie"],
    "relations": ["ACTED_IN"],
    "properties": {"Person": ["name"], "Movie": ["title"]}
  }

  ```

#### 技术实现

**极简demo版--纯Prompt生成**

> 直接通过设计Prompt，使用LLM，让Prompt->Cypher。这个过程让大模型自己进行：实体抽取，关系理解，模式拼装。
>
> - 设计Prompt：通过设计好的prompt,可以简化以上流程，代码友好
> - 后处理：结合生成后的后处理，保证生成的质量

具体实现

存在的潜在问题：

- 实体抽取或关系理解失败：Cypher语法正确，但节点、关系也许压根在KG中不存在

#### 业界优化方法

> 以下策略多聚焦于Prompt工程与工程设计，可以进行组合使用：
>
> - V1版（快速搭建，保证高响应的同时，还有不错的召回与精度）：
>   1. Schema中，使用动态Schema(sub_Schema)剪裁
>   2. few-shot中，动态示例检索
>   3. 执行后验证，保证生成可以执行
> - V2版（质量）：
>   1. Schema中，动态Schema裁剪，并对Schema进行增强
>   2. CoT分解
>   3. 候选重排序
>   4. 用户反馈闭环
> - V3（大型Schema）
>   1. 分层Schema
>   2. 两阶段生成
>   3. 规则增强
>   4. Schema缓存与索引（）

##### Schema的重表示与注入优化

> 分层与动态生成sub_schema,或对生成的sub_schema进行丰富

- 结构化表示：不要一次性塞入完整Schema，而是结构化f分层处理（50个节点以上，建议使用分层化处理）

  ```python
  # 差的做法：平铺所有信息
  schema_text = "节点：Person, Movie, Company... 关系：ACTED_IN, WORKS_FOR..."

  # 好的做法：结构化表示
  schema_structured = {
      "核心实体": {
          "Person": {
              "属性": ["name(姓名)", "age(年龄)"],
              "出边关系": ["ACTED_IN->Movie", "WORKS_FOR->Company"]
          },
          "Movie": {
              "属性": ["title(片名)", "year(年份)"],
              "入边关系": ["Person-ACTED_IN->", "Person-DIRECTED->"]
          }
      },
      "关系详情": {
          "ACTED_IN": {
              "含义": "人物出演电影",
              "属性": ["role(角色名)"],
              "示例": "(tom:Person)-[:ACTED_IN {role:'Forrest'}]->(movie:Movie)"
          }
      }
  }
  ```
- 动态裁剪（最重要）：根据问题只注入相关的Schema片段。这里需要进行 `<font color=orange>`实体抽取与关系抽取 `</font>`。获取Schema的子图表示--用于后续精准的模式匹配，提高大模型的生成质量

  * 用Embedding检索相关Schema元素
  * 用规则匹配关键词（"工作于"→WORKS_FOR, "出演"→ACTED_IN）
  * 用小模型做Schema路由

  ```python

  def get_relevant_schema(question, full_schema):
      # 步骤1：实体识别
      entities = extract_entities(question)  # "汤姆·汉克斯" -> Person

      # 步骤2：意图识别
      intent = classify_intent(question)  # "演过什么" -> ACTED_IN关系

      # 步骤3：Schema子图提取
      relevant_schema = {
          "涉及节点": ["Person", "Movie"],
          "涉及关系": ["ACTED_IN"],
          "关键属性": {
              "Person": ["name"],
              "Movie": ["title"]
          }
      }
      return relevant_schema

  # 问题："汤姆·汉克斯演过什么电影？"
  # 只注入Person、Movie、ACTED_IN，而不是全部100+个节点类型

  ```
- Schema示例增强。丰富prompt的方式进行优化

  ```python
  schema_with_examples = {
      "ACTED_IN关系": {
          "说明": "人物出演电影",
          "标准查询模板": [
              {
                  "问题类型": "某人演过什么",
                  "Cypher模板": "MATCH (p:Person {name: $person_name})-[:ACTED_IN]->(m:Movie) RETURN m.title",
                  "示例": "谁演过《阿甘正传》 -> MATCH (p:Person)-[:ACTED_IN]->(m:Movie {title: '阿甘正传'}) RETURN p.name"
              }
          ]
      }
  }
  ```
- ad

##### Few-shot示例优化

- 动态示例检索：提前写好一下few-shot,将其存到example_store中，将NL查询与例子进行top-k匹配，这样就可以实现动态的更精准的构建Prompt
- 难度分层示例：准备不同复杂度的示例（简单查询，单跳关系，多跳查询，聚合查询），需要根据问题复杂度现在示例

##### 多步推理框架

- Chain-of-Thought：
  1. 理解问题：实体，关系
  2. Schema匹配：实体映射，关系映射
  3. 生成Cypher查询
- 两阶段生成：
  1. 根据LLM与查询，生成查询计划（不要生成Cypher）
  2. 根据查询计划，生成（Cypher）

##### 约束与验证

- 语法约束生成：使用结构化输出（如OpenAI的JSON mode）
- 执行后修复：
  1. 语法检查
  2. Schema一致性
  3. 执行测试（错误时，让模型进行重新执行，设置异常执行次数）

##### 混合策略

- 规则增强的LLM：对常见模式用规则，复杂问题用LLM
- 候选生成+重排序：生成多个Cypher,进行评估，并进行重排

##### 工程的长期选择

- Schema缓存与索引
  ```python
  # 预处理Schema
  class SchemaIndex:
      def __init__(self, schema):
          self.node_index = build_embedding_index(schema['nodes'])
          self.relation_index = build_embedding_index(schema['relations'])
          self.templates = extract_query_templates(schema)

      def get_relevant_schema(self, question):
          # 快速检索相关部分
          relevant_nodes = self.node_index.search(question, top_k=5)
          relevant_relations = self.relation_index.search(question, top_k=3)
          return build_sub_schema(relevant_nodes, relevant_relations)
  ```
- 用户反馈闭环
  ```python
  # 收集用户反馈
  if user_confirms_result(cypher, result):
      # 将成功案例加入示例库
      example_store.add({
          "question": question,
          "cypher": cypher,
          "feedback": "positive"
      })
  else:
      # 记录失败案例用于分析
      log_failure(question, cypher, user_feedback)
  ```


#### 黑盒技术

> 这些都是高效应的规则实现。这里主要包括：
>
> 1. 动态Schema裁剪的完整实现
> 2. 评估查询复杂度评估的实现
